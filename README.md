###  **[Code and Datasets]: Academic Expert Finding via K-core based Embedding over Heterogeneous Graphs**

#### 1. Introduction

This is a description of the code used for the experiments described in the paper titled "Academic Expert Finding via K-core based Embedding over Heterogeneous Graphs" by Xiaoliang Xu, Jun Liu and Yuxiang Wang. The code and datasets are available at [https://github.com/leleyi/Kcore_Expert_Finding/tree/](https://github.com/leleyi/Kcore_Expert_Finding/tree/main)

#### 2. Requirements

Our code \cite{code} were implemented in Python3.8, the experiments have been run on a Linux server with two 24 cores CPU (Intel(R) 6248R 3.0GHZ) and 768GB memory, as well as 8 Tesla V100s GPUs (32G memory).

#### 3. DataSets

We used three real-work academic networks: Aminer, DBLP, and ACM. Each one provides the various relations among authors, papers, topics, etc., in a heterogeneous graph. All the original networks are provided in [data](https://drive.google.com/drive/folders/1pKug-nExGUmPvVf13xoFpFOcw5Dybk5b?usp=sharing). 

#### 4. Parameters

We implemented our solution based on an open source NLP project HuggingFace providing many pre-trained models. The default parameters are: $(k,\mathcal{P})$-core for $k$ = $4$ and $\mathcal{P}\in\{P$-$A$-$P$, $P$-$T$-$P$, $P$-$P\}$ (we use $P$-$A$-$P$ and $P$-$T$-$P$ together as default), sampling ratio $f$ = $0.3$ for training data generation, near negative strategy for negative samples collection (collect $s$ = $3$ negative samples for per positive sample), top-$m$ papers retrieval for $m$ = $1000$, and top-$n$ experts finding for $n$ = $20$. Moreover, we trained our model by setting the margin of our loss function as $c$ = $1$, epochs = $4$, and the batch size of 64 for gradient accumulation.

#### 5. Usage

Python 3.8 is required by installing via pip. Optionally, we create a new environment (with conda):

```shell
conda create --name expert_finding python=3.8 pip
conda activate expert_finding
```

Then run:

```
git clone https://github.com/leleyi/Kcore_Expert_Finding.git
cd Kcore_Expert_Finding
pip install -r requirements.txt  
```

##### 5.1 Data Pre-processing and Ground Truth Generation

We run this script (in the *script* folder) to pre-process the original datasets. All the processed datasets and some statistics are reported in the *data_info* folder. Besides, the ground truths are also generated by using this script.

````python
cd script
python data_processing.py 
````

##### 5.2 Model Train

We train our model by using the following script (in *finetune* folder). All the arguments for this script are given as: *trining data, pre-trained model, output_dir, hyperparameter1, hyperparameter2*.

````
cd finetune
python train_model.py --triple "./triplets" --model "model_name" --save_dir "./" --batch-size 64 --num-epochs 4
````

##### 5.3 Effectiveness Evaluation

We run the following scripts to evaluate the effectiveness: first line is for ours, second line is for network embedding based methods, and third line is for content embedding based methods.

````python
python efficiency_kcorebase.py # our model
python efficiency_network.py # Text-based query based on network embedding, e.g., GVNRT, IDNE
python efficiency_content.py # Text-based query based on content embedding, e.g., GloVe, SBERT
````

##### 5.4 Effect of different meta-paths

We run this script to evaluate the effect of different meta-paths on the effectiveness. Including *P-A-P, P-T-P, P-P, P-A-P$\cap$ P-T-P-, P-P$\cap$ P-T-P, P-A-P$\cap$ P-P, P-A-P$\cap$ P-P$\cap$ P-T-P*.

```
python effect_metapath.py
```

#####  5.5 Parameter Sensitivity

In order to explore the effect of different parameters on our model, such as *sampling ratio*, *the size $k$ of $k$-core*, etc., we run the following script to get the evaluation results.

```
python parameters.py
```

All experimental results will be saved in the *res* file, and you can find the specific results of each query in the */result* directory 
